
Optimize: 0.98 * loss_align(alpha=2) + 0.96 * loss_uniform(t=2)
Files already downloaded and verified
Files already downloaded and verified
Epoch 0/200	It 0/137	align_loss 1.161096 (1.161096)	uniform_loss -2.498033 (-2.498033)	total_loss -1.312747 (-1.312747)	iter_time 9.161694 (9.161694)
Epoch 0/200	It 40/137	align_loss 0.483436 (0.284989)	uniform_loss -1.332212 (-0.799442)	total_loss -0.838704 (-0.508517)	iter_time 0.205991 (0.417875)
Epoch 0/200	It 80/137	align_loss 0.741560 (0.430773)	uniform_loss -2.365425 (-1.322623)	total_loss -1.608416 (-0.882875)	iter_time 0.205363 (0.310581)
Epoch 0/200	It 120/137	align_loss 0.807677 (0.562457)	uniform_loss -2.938164 (-1.787877)	total_loss -2.113661 (-1.213702)	iter_time 0.206237 (0.274466)
dual var 1.3937622268994647, slack 0.37292889356613157
Traceback (most recent call last):
  File "/home/chiche/align_uniform-1/examples/stl10/main.py", line 196, in <module>
    main()
  File "/home/chiche/align_uniform-1/examples/stl10/main.py", line 187, in main
    val_acc = train_linear(encoder, lin_train_loader, lin_val_loader, opt)
  File "/home/chiche/align_uniform-1/examples/stl10/linear_eval.py", line 131, in train_linear
    eval_numel = encoder(sample.unsqueeze(0).to(opt.gpus[0]), layer_index=opt.lin_layer_index).numel()
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
TypeError: Caught TypeError in replica 1 on device 1.
Original Traceback (most recent call last):
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/home/chiche/miniconda3/envs/daug/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
TypeError: forward() missing 1 required positional argument: 'x'